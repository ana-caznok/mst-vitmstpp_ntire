{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import glob \n",
    "import time \n",
    "import h5py\n",
    "import cv2\n",
    "import torchinfo \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from hsi_dataset import TrainDataset, ValidDataset\n",
    "from architecture import *\n",
    "from utils import *\n",
    "\n",
    "import datetime\n",
    "import wandb\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['hscnn_plus', 'restormer','mst_plus_plus' ,'vitmstpp', 'vitmstpp_pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "hscnn_plus\n",
      "hscnn_plus_128\n",
      "TORCHINFO\n",
      "HSCNN_Plus(\n",
      "  (ddfn): ddfn(\n",
      "    (conv_up1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv_up2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (conv_down1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv_down2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dfus_blocks): Sequential(\n",
      "      (0): dfus_block(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): dfus_block(\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): dfus_block(\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): dfus_block(\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): dfus_block(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): dfus_block(\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): dfus_block(\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): dfus_block(\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): dfus_block(\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): dfus_block(\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): dfus_block(\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): dfus_block(\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): dfus_block(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): dfus_block(\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): dfus_block(\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): dfus_block(\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): dfus_block(\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): dfus_block(\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (18): dfus_block(\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (19): dfus_block(\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (20): dfus_block(\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (21): dfus_block(\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (22): dfus_block(\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (23): dfus_block(\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (24): dfus_block(\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (25): dfus_block(\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (26): dfus_block(\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (27): dfus_block(\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (28): dfus_block(\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (29): dfus_block(\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_out): Conv2d(1088, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n",
      "GMac:141.76953125\n",
      "Params:4645504\n",
      "hscnn_plus_256\n",
      "TORCHINFO\n",
      "HSCNN_Plus(\n",
      "  (ddfn): ddfn(\n",
      "    (conv_up1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv_up2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (conv_down1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (conv_down2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (dfus_blocks): Sequential(\n",
      "      (0): dfus_block(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): dfus_block(\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): dfus_block(\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): dfus_block(\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): dfus_block(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): dfus_block(\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (6): dfus_block(\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (7): dfus_block(\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (8): dfus_block(\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (9): dfus_block(\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (10): dfus_block(\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (11): dfus_block(\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (12): dfus_block(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (13): dfus_block(\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (14): dfus_block(\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (15): dfus_block(\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (16): dfus_block(\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (17): dfus_block(\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (18): dfus_block(\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (19): dfus_block(\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (20): dfus_block(\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (21): dfus_block(\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (22): dfus_block(\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (23): dfus_block(\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (24): dfus_block(\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (25): dfus_block(\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (26): dfus_block(\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (27): dfus_block(\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (28): dfus_block(\n",
      "        (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (29): dfus_block(\n",
      "        (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_up1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_up2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_down1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (conv_down2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (conv_fution): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv_out): Conv2d(1088, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n",
      "GMac:567.078125\n",
      "Params:4645504\n",
      "hscnn_plus_384\n",
      "TORCHINFO\n",
      "hscnn_plus_512\n",
      "TORCHINFO\n",
      "hscnn_plus_768\n",
      "TORCHINFO\n",
      "hscnn_plus_1024\n",
      "TORCHINFO\n",
      " \n",
      " \n",
      "restormer\n",
      "restormer_128\n",
      "TORCHINFO\n",
      "Restormer(\n",
      "  (patch_embed): OverlapPatchEmbed(\n",
      "    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (encoder_level1): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
      "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
      "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down1_2): Downsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelUnShuffle()\n",
      "    )\n",
      "  )\n",
      "  (encoder_level2): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down2_3): Downsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelUnShuffle()\n",
      "    )\n",
      "  )\n",
      "  (encoder_level3): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down3_4): Downsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelUnShuffle()\n",
      "    )\n",
      "  )\n",
      "  (latent): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
      "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
      "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
      "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
      "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up4_3): Upsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelShuffle(upscale_factor=2)\n",
      "    )\n",
      "  )\n",
      "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (decoder_level3): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up3_2): Upsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelShuffle(upscale_factor=2)\n",
      "    )\n",
      "  )\n",
      "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (decoder_level2): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up2_1): Upsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelShuffle(upscale_factor=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder_level1): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (refinement): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (skip_conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (output): Conv2d(96, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::rsub encountered 2 time(s)\n",
      "Unsupported operator aten::reflection_pad2d encountered 1 time(s)\n",
      "Unsupported operator aten::mul encountered 532 time(s)\n",
      "Unsupported operator aten::mul_ encountered 115 time(s)\n",
      "Unsupported operator aten::mean encountered 46 time(s)\n",
      "Unsupported operator aten::var encountered 46 time(s)\n",
      "Unsupported operator aten::sub encountered 46 time(s)\n",
      "Unsupported operator aten::add encountered 139 time(s)\n",
      "Unsupported operator aten::sqrt encountered 46 time(s)\n",
      "Unsupported operator aten::div encountered 92 time(s)\n",
      "Unsupported operator aten::norm encountered 46 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 46 time(s)\n",
      "Unsupported operator aten::expand_as encountered 46 time(s)\n",
      "Unsupported operator aten::softmax encountered 23 time(s)\n",
      "Unsupported operator aten::gelu encountered 23 time(s)\n",
      "Unsupported operator aten::pixel_shuffle encountered 3 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMac:43.666202545166016\n",
      "Params:15108705\n",
      "restormer_256\n",
      "TORCHINFO\n",
      "Restormer(\n",
      "  (patch_embed): OverlapPatchEmbed(\n",
      "    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (encoder_level1): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
      "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
      "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down1_2): Downsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelUnShuffle()\n",
      "    )\n",
      "  )\n",
      "  (encoder_level2): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down2_3): Downsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelUnShuffle()\n",
      "    )\n",
      "  )\n",
      "  (encoder_level3): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down3_4): Downsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelUnShuffle()\n",
      "    )\n",
      "  )\n",
      "  (latent): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
      "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
      "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
      "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
      "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
      "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up4_3): Upsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelShuffle(upscale_factor=2)\n",
      "    )\n",
      "  )\n",
      "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (decoder_level3): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
      "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up3_2): Upsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelShuffle(upscale_factor=2)\n",
      "    )\n",
      "  )\n",
      "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (decoder_level2): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up2_1): Upsample(\n",
      "    (body): Sequential(\n",
      "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): PixelShuffle(upscale_factor=2)\n",
      "    )\n",
      "  )\n",
      "  (decoder_level1): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (refinement): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
      "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (norm2): LayerNorm(\n",
      "        (body): WithBias_LayerNorm()\n",
      "      )\n",
      "      (ffn): FeedForward(\n",
      "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
      "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (skip_conv): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (output): Conv2d(96, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::rsub encountered 2 time(s)\n",
      "Unsupported operator aten::reflection_pad2d encountered 1 time(s)\n",
      "Unsupported operator aten::mul encountered 532 time(s)\n",
      "Unsupported operator aten::mul_ encountered 115 time(s)\n",
      "Unsupported operator aten::mean encountered 46 time(s)\n",
      "Unsupported operator aten::var encountered 46 time(s)\n",
      "Unsupported operator aten::sub encountered 46 time(s)\n",
      "Unsupported operator aten::add encountered 139 time(s)\n",
      "Unsupported operator aten::sqrt encountered 46 time(s)\n",
      "Unsupported operator aten::div encountered 92 time(s)\n",
      "Unsupported operator aten::norm encountered 46 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 46 time(s)\n",
      "Unsupported operator aten::expand_as encountered 46 time(s)\n",
      "Unsupported operator aten::softmax encountered 23 time(s)\n",
      "Unsupported operator aten::gelu encountered 23 time(s)\n",
      "Unsupported operator aten::pixel_shuffle encountered 3 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMac:174.66481018066406\n",
      "Params:15108705\n",
      "restormer_384\n",
      "TORCHINFO\n",
      "restormer_512\n",
      "TORCHINFO\n",
      "restormer_768\n",
      "TORCHINFO\n",
      "restormer_1024\n",
      "TORCHINFO\n",
      " \n",
      " \n",
      "mst_plus_plus\n",
      "mst_plus_plus_128\n",
      "TORCHINFO\n",
      "MST_Plus_Plus(\n",
      "  (conv_in): Conv2d(3, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (body): Sequential(\n",
      "    (0): MST(\n",
      "      (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (encoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottleneck): MSAB(\n",
      "        (blocks): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MS_MSA(\n",
      "              (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "              (pos_emb): Sequential(\n",
      "                (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                (1): GELU()\n",
      "                (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "              )\n",
      "            )\n",
      "            (1): PreNorm(\n",
      "              (fn): FeedForward(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                  (3): GELU()\n",
      "                  (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "              )\n",
      "              (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): MST(\n",
      "      (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (encoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottleneck): MSAB(\n",
      "        (blocks): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MS_MSA(\n",
      "              (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "              (pos_emb): Sequential(\n",
      "                (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                (1): GELU()\n",
      "                (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "              )\n",
      "            )\n",
      "            (1): PreNorm(\n",
      "              (fn): FeedForward(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                  (3): GELU()\n",
      "                  (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "              )\n",
      "              (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): MST(\n",
      "      (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (encoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottleneck): MSAB(\n",
      "        (blocks): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MS_MSA(\n",
      "              (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "              (pos_emb): Sequential(\n",
      "                (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                (1): GELU()\n",
      "                (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "              )\n",
      "            )\n",
      "            (1): PreNorm(\n",
      "              (fn): FeedForward(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                  (3): GELU()\n",
      "                  (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "              )\n",
      "              (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_out): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::rsub encountered 2 time(s)\n",
      "Unsupported operator aten::reflection_pad2d encountered 1 time(s)\n",
      "Unsupported operator aten::mul encountered 45 time(s)\n",
      "Unsupported operator aten::norm encountered 30 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 30 time(s)\n",
      "Unsupported operator aten::expand_as encountered 30 time(s)\n",
      "Unsupported operator aten::div encountered 30 time(s)\n",
      "Unsupported operator aten::softmax encountered 15 time(s)\n",
      "Unsupported operator aten::add_ encountered 16 time(s)\n",
      "Unsupported operator aten::gelu encountered 45 time(s)\n",
      "Unsupported operator aten::add encountered 48 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "body.0.lrelu, body.1.lrelu, body.2.lrelu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMac:10.379768371582031\n",
      "Params:1619625\n",
      "mst_plus_plus_256\n",
      "TORCHINFO\n",
      "MST_Plus_Plus(\n",
      "  (conv_in): Conv2d(3, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (body): Sequential(\n",
      "    (0): MST(\n",
      "      (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (encoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottleneck): MSAB(\n",
      "        (blocks): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MS_MSA(\n",
      "              (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "              (pos_emb): Sequential(\n",
      "                (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                (1): GELU()\n",
      "                (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "              )\n",
      "            )\n",
      "            (1): PreNorm(\n",
      "              (fn): FeedForward(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                  (3): GELU()\n",
      "                  (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "              )\n",
      "              (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (1): MST(\n",
      "      (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (encoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottleneck): MSAB(\n",
      "        (blocks): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MS_MSA(\n",
      "              (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "              (pos_emb): Sequential(\n",
      "                (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                (1): GELU()\n",
      "                (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "              )\n",
      "            )\n",
      "            (1): PreNorm(\n",
      "              (fn): FeedForward(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                  (3): GELU()\n",
      "                  (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "              )\n",
      "              (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "    (2): MST(\n",
      "      (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (encoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (bottleneck): MSAB(\n",
      "        (blocks): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MS_MSA(\n",
      "              (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "              (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "              (pos_emb): Sequential(\n",
      "                (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                (1): GELU()\n",
      "                (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "              )\n",
      "            )\n",
      "            (1): PreNorm(\n",
      "              (fn): FeedForward(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                  (3): GELU()\n",
      "                  (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "              )\n",
      "              (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder_layers): ModuleList(\n",
      "        (0): ModuleList(\n",
      "          (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                  (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ModuleList(\n",
      "          (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "          (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): MSAB(\n",
      "            (blocks): ModuleList(\n",
      "              (0): ModuleList(\n",
      "                (0): MS_MSA(\n",
      "                  (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                  (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                  (pos_emb): Sequential(\n",
      "                    (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (1): PreNorm(\n",
      "                  (fn): FeedForward(\n",
      "                    (net): Sequential(\n",
      "                      (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                      (3): GELU()\n",
      "                      (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_out): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::rsub encountered 2 time(s)\n",
      "Unsupported operator aten::reflection_pad2d encountered 1 time(s)\n",
      "Unsupported operator aten::mul encountered 45 time(s)\n",
      "Unsupported operator aten::norm encountered 30 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 30 time(s)\n",
      "Unsupported operator aten::expand_as encountered 30 time(s)\n",
      "Unsupported operator aten::div encountered 30 time(s)\n",
      "Unsupported operator aten::softmax encountered 15 time(s)\n",
      "Unsupported operator aten::add_ encountered 16 time(s)\n",
      "Unsupported operator aten::gelu encountered 45 time(s)\n",
      "Unsupported operator aten::add encountered 48 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "body.0.lrelu, body.1.lrelu, body.2.lrelu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMac:41.519073486328125\n",
      "Params:1619625\n",
      "mst_plus_plus_384\n",
      "TORCHINFO\n",
      "mst_plus_plus_512\n",
      "TORCHINFO\n",
      "mst_plus_plus_768\n",
      "TORCHINFO\n",
      "mst_plus_plus_1024\n",
      "TORCHINFO\n",
      " \n",
      " \n",
      "vitmstpp\n",
      "Initialized VITMSTPPUNet with MSTPP stages: 6 and normalization instance\n",
      "vitmstpp_128\n",
      "TORCHINFO\n",
      "WARNING: VITMSTPPUNET performing interpolation to ViT required 1024 spatial resolution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VITMSTPP(\n",
      "  (vit): ImageEncoderViT(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (neck): Sequential(\n",
      "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): LayerNorm2d()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (3): LayerNorm2d()\n",
      "    )\n",
      "  )\n",
      "  (compression_convolution): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (4): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    )\n",
      "    (residual_connection): Conv2d(7, 4, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (mstpp): MST_Plus_Plus(\n",
      "    (conv_in): Conv2d(7, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (body): Sequential(\n",
      "      (0): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_out): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (upsample_4): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  (upsample_2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  (padding): Identity()\n",
      "  (decoding_convolution): Sequential(\n",
      "    (0): DoubleConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(42, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(62, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (3): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(62, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "      (residual_connection): Conv2d(42, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): DoubleConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(62, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (3): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "      (residual_connection): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (out_conv): Conv2d(31, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "Unsupported operator aten::add encountered 192 time(s)\n",
      "Unsupported operator aten::rsub encountered 18 time(s)\n",
      "Unsupported operator aten::add_ encountered 79 time(s)\n",
      "Unsupported operator aten::mul encountered 244 time(s)\n",
      "Unsupported operator aten::div encountered 134 time(s)\n",
      "Unsupported operator aten::sub encountered 52 time(s)\n",
      "Unsupported operator aten::softmax encountered 42 time(s)\n",
      "Unsupported operator aten::gelu encountered 102 time(s)\n",
      "Unsupported operator aten::mean encountered 4 time(s)\n",
      "Unsupported operator aten::pow encountered 2 time(s)\n",
      "Unsupported operator aten::sqrt encountered 2 time(s)\n",
      "Unsupported operator aten::leaky_relu_ encountered 6 time(s)\n",
      "Unsupported operator aten::reflection_pad2d encountered 1 time(s)\n",
      "Unsupported operator aten::norm encountered 60 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 60 time(s)\n",
      "Unsupported operator aten::expand_as encountered 60 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mstpp.body.0.lrelu, mstpp.body.1.lrelu, mstpp.body.2.lrelu, mstpp.body.3.lrelu, mstpp.body.4.lrelu, mstpp.body.5.lrelu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMac:910.0643557310104\n",
      "Params:92991682\n",
      "vitmstpp_256\n",
      "TORCHINFO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VITMSTPP(\n",
      "  (vit): ImageEncoderViT(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (neck): Sequential(\n",
      "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): LayerNorm2d()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (3): LayerNorm2d()\n",
      "    )\n",
      "  )\n",
      "  (compression_convolution): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (4): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    )\n",
      "    (residual_connection): Conv2d(7, 4, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (mstpp): MST_Plus_Plus(\n",
      "    (conv_in): Conv2d(7, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (body): Sequential(\n",
      "      (0): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_out): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (upsample_4): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  (upsample_2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  (padding): Identity()\n",
      "  (decoding_convolution): Sequential(\n",
      "    (0): DoubleConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(42, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(62, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (3): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(62, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "      (residual_connection): Conv2d(42, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): DoubleConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(62, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (3): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "      (residual_connection): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (out_conv): Conv2d(31, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "Unsupported operator aten::add encountered 192 time(s)\n",
      "Unsupported operator aten::rsub encountered 18 time(s)\n",
      "Unsupported operator aten::add_ encountered 79 time(s)\n",
      "Unsupported operator aten::mul encountered 244 time(s)\n",
      "Unsupported operator aten::div encountered 134 time(s)\n",
      "Unsupported operator aten::sub encountered 52 time(s)\n",
      "Unsupported operator aten::softmax encountered 42 time(s)\n",
      "Unsupported operator aten::gelu encountered 102 time(s)\n",
      "Unsupported operator aten::mean encountered 4 time(s)\n",
      "Unsupported operator aten::pow encountered 2 time(s)\n",
      "Unsupported operator aten::sqrt encountered 2 time(s)\n",
      "Unsupported operator aten::leaky_relu_ encountered 6 time(s)\n",
      "Unsupported operator aten::reflection_pad2d encountered 1 time(s)\n",
      "Unsupported operator aten::norm encountered 60 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 60 time(s)\n",
      "Unsupported operator aten::expand_as encountered 60 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mstpp.body.0.lrelu, mstpp.body.1.lrelu, mstpp.body.2.lrelu, mstpp.body.3.lrelu, mstpp.body.4.lrelu, mstpp.body.5.lrelu\n",
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMac:922.1787194013596\n",
      "Params:92991682\n",
      "vitmstpp_384\n",
      "TORCHINFO\n",
      "vitmstpp_512\n",
      "TORCHINFO\n",
      "vitmstpp_768\n",
      "TORCHINFO\n",
      "vitmstpp_1024\n",
      "TORCHINFO\n",
      " \n",
      " \n",
      "vitmstpp_pad\n",
      "Initialized VITMSTPPUNet with MSTPP stages: 6 and normalization instance\n",
      "vitmstpp_pad_128\n",
      "TORCHINFO\n",
      "WARNING: VITMSTPPUNET performing interpolation to ViT required 1024 spatial resolution.\n",
      "VITMSTPP_Pad(\n",
      "  (vit): ImageEncoderViT(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (neck): Sequential(\n",
      "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): LayerNorm2d()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (3): LayerNorm2d()\n",
      "    )\n",
      "  )\n",
      "  (compression_convolution): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (4): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    )\n",
      "    (residual_connection): Conv2d(7, 4, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (mstpp): MST_Plus_Plus(\n",
      "    (conv_in): Conv2d(7, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (body): Sequential(\n",
      "      (0): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_out): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (upsample_4): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  (upsample_2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  (padding): Identity()\n",
      "  (decoding_convolution): Sequential(\n",
      "    (0): DoubleConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(42, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(62, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (3): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(62, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "      (residual_connection): Conv2d(42, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): DoubleConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(62, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (3): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "      (residual_connection): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (out_conv): Conv2d(31, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "Unsupported operator aten::rsub encountered 26 time(s)\n",
      "Unsupported operator aten::reflection_pad2d encountered 3 time(s)\n",
      "Unsupported operator aten::sub encountered 56 time(s)\n",
      "Unsupported operator aten::add encountered 196 time(s)\n",
      "Unsupported operator aten::add_ encountered 79 time(s)\n",
      "Unsupported operator aten::mul encountered 244 time(s)\n",
      "Unsupported operator aten::div encountered 134 time(s)\n",
      "Unsupported operator aten::softmax encountered 42 time(s)\n",
      "Unsupported operator aten::gelu encountered 102 time(s)\n",
      "Unsupported operator aten::mean encountered 4 time(s)\n",
      "Unsupported operator aten::pow encountered 2 time(s)\n",
      "Unsupported operator aten::sqrt encountered 2 time(s)\n",
      "Unsupported operator aten::leaky_relu_ encountered 6 time(s)\n",
      "Unsupported operator aten::norm encountered 60 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 60 time(s)\n",
      "Unsupported operator aten::expand_as encountered 60 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mstpp.body.0.lrelu, mstpp.body.1.lrelu, mstpp.body.2.lrelu, mstpp.body.3.lrelu, mstpp.body.4.lrelu, mstpp.body.5.lrelu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMac:970.636174082756\n",
      "Params:92991682\n",
      "vitmstpp_pad_256\n",
      "TORCHINFO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VITMSTPP_Pad(\n",
      "  (vit): ImageEncoderViT(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (act): GELU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (neck): Sequential(\n",
      "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): LayerNorm2d()\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (3): LayerNorm2d()\n",
      "    )\n",
      "  )\n",
      "  (compression_convolution): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(7, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (4): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "    )\n",
      "    (residual_connection): Conv2d(7, 4, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (mstpp): MST_Plus_Plus(\n",
      "    (conv_in): Conv2d(7, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (body): Sequential(\n",
      "      (0): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (1): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (2): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (3): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (4): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "      (5): MST(\n",
      "        (embedding): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (encoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(31, 62, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): Conv2d(62, 124, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          )\n",
      "        )\n",
      "        (bottleneck): MSAB(\n",
      "          (blocks): ModuleList(\n",
      "            (0): ModuleList(\n",
      "              (0): MS_MSA(\n",
      "                (to_q): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_k): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (to_v): Linear(in_features=124, out_features=124, bias=False)\n",
      "                (proj): Linear(in_features=124, out_features=124, bias=True)\n",
      "                (pos_emb): Sequential(\n",
      "                  (0): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                  (1): GELU()\n",
      "                  (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                )\n",
      "              )\n",
      "              (1): PreNorm(\n",
      "                (fn): FeedForward(\n",
      "                  (net): Sequential(\n",
      "                    (0): Conv2d(124, 496, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (1): GELU()\n",
      "                    (2): Conv2d(496, 496, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=496, bias=False)\n",
      "                    (3): GELU()\n",
      "                    (4): Conv2d(496, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  )\n",
      "                )\n",
      "                (norm): LayerNorm((124,), eps=1e-05, elementwise_affine=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (decoder_layers): ModuleList(\n",
      "          (0): ModuleList(\n",
      "            (0): ConvTranspose2d(124, 62, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(124, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_k): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (to_v): Linear(in_features=62, out_features=62, bias=False)\n",
      "                    (proj): Linear(in_features=62, out_features=62, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=62, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(62, 248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(248, 248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=248, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(248, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((62,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ModuleList(\n",
      "            (0): ConvTranspose2d(62, 31, kernel_size=(2, 2), stride=(2, 2))\n",
      "            (1): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): MSAB(\n",
      "              (blocks): ModuleList(\n",
      "                (0): ModuleList(\n",
      "                  (0): MS_MSA(\n",
      "                    (to_q): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_k): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (to_v): Linear(in_features=31, out_features=31, bias=False)\n",
      "                    (proj): Linear(in_features=31, out_features=31, bias=True)\n",
      "                    (pos_emb): Sequential(\n",
      "                      (0): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                      (1): GELU()\n",
      "                      (2): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=31, bias=False)\n",
      "                    )\n",
      "                  )\n",
      "                  (1): PreNorm(\n",
      "                    (fn): FeedForward(\n",
      "                      (net): Sequential(\n",
      "                        (0): Conv2d(31, 124, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (1): GELU()\n",
      "                        (2): Conv2d(124, 124, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=124, bias=False)\n",
      "                        (3): GELU()\n",
      "                        (4): Conv2d(124, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                      )\n",
      "                    )\n",
      "                    (norm): LayerNorm((31,), eps=1e-05, elementwise_affine=True)\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (mapping): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (lrelu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (conv_out): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (upsample_4): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  (upsample_2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  (padding): Identity()\n",
      "  (decoding_convolution): Sequential(\n",
      "    (0): DoubleConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(42, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(62, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (3): Conv2d(62, 62, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(62, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "      (residual_connection): Conv2d(42, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): DoubleConv(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(62, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "        (3): Conv2d(31, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(31, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (5): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "      )\n",
      "      (residual_connection): Conv2d(62, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (out_conv): Conv2d(31, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
      "Unsupported operator aten::rsub encountered 22 time(s)\n",
      "Unsupported operator aten::sub encountered 56 time(s)\n",
      "Unsupported operator aten::reflection_pad2d encountered 2 time(s)\n",
      "Unsupported operator aten::add encountered 192 time(s)\n",
      "Unsupported operator aten::add_ encountered 79 time(s)\n",
      "Unsupported operator aten::mul encountered 244 time(s)\n",
      "Unsupported operator aten::div encountered 134 time(s)\n",
      "Unsupported operator aten::softmax encountered 42 time(s)\n",
      "Unsupported operator aten::gelu encountered 102 time(s)\n",
      "Unsupported operator aten::mean encountered 4 time(s)\n",
      "Unsupported operator aten::pow encountered 2 time(s)\n",
      "Unsupported operator aten::sqrt encountered 2 time(s)\n",
      "Unsupported operator aten::leaky_relu_ encountered 6 time(s)\n",
      "Unsupported operator aten::norm encountered 60 time(s)\n",
      "Unsupported operator aten::clamp_min encountered 60 time(s)\n",
      "Unsupported operator aten::expand_as encountered 60 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "mstpp.body.0.lrelu, mstpp.body.1.lrelu, mstpp.body.2.lrelu, mstpp.body.3.lrelu, mstpp.body.4.lrelu, mstpp.body.5.lrelu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMac:970.636174082756\n",
      "Params:92991682\n",
      "vitmstpp_pad_384\n",
      "TORCHINFO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/datassd/icasp/miniconda3/envs/mst_torch/lib/python3.8/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vitmstpp_pad_512\n",
      "TORCHINFO\n",
      "vitmstpp_pad_768\n",
      "TORCHINFO\n",
      "vitmstpp_pad_1024\n",
      "TORCHINFO\n"
     ]
    }
   ],
   "source": [
    "models_dict = {}\n",
    "inputs = [128, 256, 384, 512, 768, 1024]\n",
    "macs_dict = {}\n",
    "for md in models:\n",
    "    print(' ')\n",
    "    print(' ') \n",
    "    print(md)\n",
    "    model = model_generator(md).cuda()\n",
    "    macs_dict[md] = []\n",
    "    for i in inputs: \n",
    "        torch.cuda.empty_cache()\n",
    "        nm = md +'_' + str(i)\n",
    "        print(nm)\n",
    "        models_dict[nm] = {}\n",
    "        print('TORCHINFO')\n",
    "        try: \n",
    "            summary_str = str(torchinfo.summary(model, input_size=(2,3,i,i)))\n",
    "            models_dict[nm]['MACs'] = summary_str.split('Total mult-adds ')[1].split('\\n')[0]\n",
    "            models_dict[nm]['tot_size'] = summary_str.split('Estimated Total Size ')[1].split('\\n')[0]\n",
    "            models_dict[nm]['trainable'] = int(summary_str.split('Trainable params: ')[1].split('\\n')[0].replace(',',''))\n",
    "        except: \n",
    "            del model \n",
    "            torch.cuda.empty_cache()\n",
    "            print('NOT ABLE TO SCALE TO 1024')\n",
    "            print(nm)\n",
    "\n",
    "        if i <= 256: \n",
    "            n_params, gmac = my_summary(model, i, i, 3, 2)\n",
    "            models_dict[nm]['n_params'] = int(n_params)\n",
    "            models_dict[nm]['gmac'] = float(gmac)\n",
    "\n",
    "        if 'T' in models_dict[nm]['MACs']: \n",
    "            macs = float(models_dict[nm]['MACs'].split(': ')[1])*1000\n",
    "            macs_dict[md].append(macs)\n",
    "        elif 'G' in models_dict[nm]['MACs']: \n",
    "            macs = float(models_dict[nm]['MACs'].split(': ')[1])\n",
    "            macs_dict[md].append(macs)\n",
    "        else:\n",
    "            print('error')\n",
    "        \n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hscnn_plus_128': {'MACs': '(G): 152.22',\n",
       "  'tot_size': '(MB): 2073.92',\n",
       "  'trainable': 4645504,\n",
       "  'n_params': 4645504,\n",
       "  'gmac': 141.76953125},\n",
       " 'hscnn_plus_256': {'MACs': '(G): 608.90',\n",
       "  'tot_size': '(MB): 8239.94',\n",
       "  'trainable': 4645504,\n",
       "  'n_params': 4645504,\n",
       "  'gmac': 567.078125},\n",
       " 'hscnn_plus_384': {'MACs': '(T): 1.37',\n",
       "  'tot_size': '(MB): 18516.64',\n",
       "  'trainable': 4645504},\n",
       " 'hscnn_plus_512': {'MACs': '(T): 2.44',\n",
       "  'tot_size': '(MB): 32904.02',\n",
       "  'trainable': 4645504},\n",
       " 'hscnn_plus_768': {'MACs': '(T): 5.48',\n",
       "  'tot_size': '(MB): 74010.82',\n",
       "  'trainable': 4645504},\n",
       " 'hscnn_plus_1024': {'MACs': '(T): 9.74',\n",
       "  'tot_size': '(MB): 131560.34',\n",
       "  'trainable': 4645504},\n",
       " 'restormer_128': {'MACs': '(G): 42.80',\n",
       "  'tot_size': '(MB): 4560.07',\n",
       "  'trainable': 15108705,\n",
       "  'n_params': 15108705,\n",
       "  'gmac': 43.666202545166016},\n",
       " 'restormer_256': {'MACs': '(G): 171.22',\n",
       "  'tot_size': '(MB): 18058.98',\n",
       "  'trainable': 15108705,\n",
       "  'n_params': 15108705,\n",
       "  'gmac': 174.66481018066406},\n",
       " 'restormer_384': {'MACs': '(G): 385.23',\n",
       "  'tot_size': '(MB): 40557.16',\n",
       "  'trainable': 15108705},\n",
       " 'restormer_512': {'MACs': '(G): 684.86',\n",
       "  'tot_size': '(MB): 72054.61',\n",
       "  'trainable': 15108705},\n",
       " 'restormer_768': {'MACs': '(T): 1.54',\n",
       "  'tot_size': '(MB): 162047.34',\n",
       "  'trainable': 15108705},\n",
       " 'restormer_1024': {'MACs': '(T): 2.74',\n",
       "  'tot_size': '(MB): 288037.15',\n",
       "  'trainable': 15108705},\n",
       " 'mst_plus_plus_128': {'MACs': '(G): 9.73',\n",
       "  'tot_size': '(MB): 1431.03',\n",
       "  'trainable': 1619625,\n",
       "  'n_params': 1619625,\n",
       "  'gmac': 10.379768371582031},\n",
       " 'mst_plus_plus_256': {'MACs': '(G): 38.92',\n",
       "  'tot_size': '(MB): 5704.70',\n",
       "  'trainable': 1619625,\n",
       "  'n_params': 1619625,\n",
       "  'gmac': 41.519073486328125},\n",
       " 'mst_plus_plus_384': {'MACs': '(G): 87.57',\n",
       "  'tot_size': '(MB): 12827.48',\n",
       "  'trainable': 1619625},\n",
       " 'mst_plus_plus_512': {'MACs': '(G): 155.69',\n",
       "  'tot_size': '(MB): 22799.37',\n",
       "  'trainable': 1619625},\n",
       " 'mst_plus_plus_768': {'MACs': '(G): 350.30',\n",
       "  'tot_size': '(MB): 51290.50',\n",
       "  'trainable': 1619625},\n",
       " 'mst_plus_plus_1024': {'MACs': '(G): 622.75',\n",
       "  'tot_size': '(MB): 91178.06',\n",
       "  'trainable': 1619625},\n",
       " 'vitmstpp_128': {'MACs': '(G): 16.49',\n",
       "  'tot_size': '(MB): 7695.43',\n",
       "  'trainable': 3320770,\n",
       "  'n_params': 92991682,\n",
       "  'gmac': 910.0643557310104},\n",
       " 'vitmstpp_256': {'MACs': '(G): 28.89',\n",
       "  'tot_size': '(MB): 8472.60',\n",
       "  'trainable': 3320770,\n",
       "  'n_params': 92991682,\n",
       "  'gmac': 922.1787194013596},\n",
       " 'vitmstpp_384': {'MACs': '(G): 49.56',\n",
       "  'tot_size': '(MB): 9767.88',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_512': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11581.27',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_768': {'MACs': '(G): 161.15',\n",
       "  'tot_size': '(MB): 16762.38',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_1024': {'MACs': '(G): 276.88',\n",
       "  'tot_size': '(MB): 24015.94',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_pad_128': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11575.37',\n",
       "  'trainable': 3320770,\n",
       "  'n_params': 92991682,\n",
       "  'gmac': 970.636174082756},\n",
       " 'vitmstpp_pad_256': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11576.55',\n",
       "  'trainable': 3320770,\n",
       "  'n_params': 92991682,\n",
       "  'gmac': 970.636174082756},\n",
       " 'vitmstpp_pad_384': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11578.51',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_pad_512': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11581.27',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_pad_768': {'MACs': '(G): 161.15',\n",
       "  'tot_size': '(MB): 16762.38',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_pad_1024': {'MACs': '(G): 276.88',\n",
       "  'tot_size': '(MB): 24015.94',\n",
       "  'trainable': 3320770}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hscnn_plus': [152.22, 608.9, 1370.0, 2440.0, 5480.0, 9740.0],\n",
       " 'restormer': [42.8, 171.22, 385.23, 684.86, 1540.0, 2740.0],\n",
       " 'mst_plus_plus': [9.73, 38.92, 87.57, 155.69, 350.3, 622.75],\n",
       " 'vitmstpp': [16.49, 28.89, 49.56, 78.49, 161.15, 276.88],\n",
       " 'vitmstpp_pad': [78.49, 78.49, 78.49, 78.49, 161.15, 276.88]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_macs(inputs, macs_dict): \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.ylabel('MACs', fontsize=16)\n",
    "    plt.xlabel('Input Size (px)', fontsize=16)\n",
    "    for k in macs_dict: \n",
    "        plt.plot(np.array(macs_dict[k]),np.array(inputs))\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hscnn_plus', 'restormer', 'mst_plus_plus', 'vitmstpp', 'vitmstpp_pad']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(macs_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.ylabel('MACs (G)', fontsize=16)\n",
    "plt.xlabel('Input Size (px)', fontsize=16)\n",
    "for k in macs_dict: \n",
    "    plt.plot(np.array(inputs),np.array(macs_dict[k]), 'o-')\n",
    "    \n",
    "plt.legend(list(macs_dict.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = '/mnt/datassd/mst_toolbox/mst-vitmstpp_ntire/'\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.ylabel('Log(MACs (G))', fontsize=18)\n",
    "plt.xlabel('Input Size (px)', fontsize=18)\n",
    "for k in macs_dict: \n",
    "    if k == 'vitmstpp_pad': \n",
    "        continue\n",
    "    else: \n",
    "        plt.plot(np.array(inputs),np.log(np.array(macs_dict[k])), 'o-')\n",
    "    \n",
    "plt.legend(list(macs_dict.keys()), fontsize = 14)\n",
    "plt.xticks(inputs, fontsize=12)\n",
    "plt.title('NTIRE scaling')\n",
    "plt.savefig(save_path + 'figure_logmacs_no-pad.png', dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hscnn_plus_128': {'MACs': '(G): 152.22',\n",
       "  'tot_size': '(MB): 2073.92',\n",
       "  'trainable': 4645504,\n",
       "  'n_params': 4645504,\n",
       "  'gmac': 141.76953125},\n",
       " 'hscnn_plus_256': {'MACs': '(G): 608.90',\n",
       "  'tot_size': '(MB): 8239.94',\n",
       "  'trainable': 4645504,\n",
       "  'n_params': 4645504,\n",
       "  'gmac': 567.078125},\n",
       " 'hscnn_plus_384': {'MACs': '(T): 1.37',\n",
       "  'tot_size': '(MB): 18516.64',\n",
       "  'trainable': 4645504},\n",
       " 'hscnn_plus_512': {'MACs': '(T): 2.44',\n",
       "  'tot_size': '(MB): 32904.02',\n",
       "  'trainable': 4645504},\n",
       " 'hscnn_plus_768': {'MACs': '(T): 5.48',\n",
       "  'tot_size': '(MB): 74010.82',\n",
       "  'trainable': 4645504},\n",
       " 'hscnn_plus_1024': {'MACs': '(T): 9.74',\n",
       "  'tot_size': '(MB): 131560.34',\n",
       "  'trainable': 4645504},\n",
       " 'restormer_128': {'MACs': '(G): 42.80',\n",
       "  'tot_size': '(MB): 4560.07',\n",
       "  'trainable': 15108705,\n",
       "  'n_params': 15108705,\n",
       "  'gmac': 43.666202545166016},\n",
       " 'restormer_256': {'MACs': '(G): 171.22',\n",
       "  'tot_size': '(MB): 18058.98',\n",
       "  'trainable': 15108705,\n",
       "  'n_params': 15108705,\n",
       "  'gmac': 174.66481018066406},\n",
       " 'restormer_384': {'MACs': '(G): 385.23',\n",
       "  'tot_size': '(MB): 40557.16',\n",
       "  'trainable': 15108705},\n",
       " 'restormer_512': {'MACs': '(G): 684.86',\n",
       "  'tot_size': '(MB): 72054.61',\n",
       "  'trainable': 15108705},\n",
       " 'restormer_768': {'MACs': '(T): 1.54',\n",
       "  'tot_size': '(MB): 162047.34',\n",
       "  'trainable': 15108705},\n",
       " 'restormer_1024': {'MACs': '(T): 2.74',\n",
       "  'tot_size': '(MB): 288037.15',\n",
       "  'trainable': 15108705},\n",
       " 'mst_plus_plus_128': {'MACs': '(G): 9.73',\n",
       "  'tot_size': '(MB): 1431.03',\n",
       "  'trainable': 1619625,\n",
       "  'n_params': 1619625,\n",
       "  'gmac': 10.379768371582031},\n",
       " 'mst_plus_plus_256': {'MACs': '(G): 38.92',\n",
       "  'tot_size': '(MB): 5704.70',\n",
       "  'trainable': 1619625,\n",
       "  'n_params': 1619625,\n",
       "  'gmac': 41.519073486328125},\n",
       " 'mst_plus_plus_384': {'MACs': '(G): 87.57',\n",
       "  'tot_size': '(MB): 12827.48',\n",
       "  'trainable': 1619625},\n",
       " 'mst_plus_plus_512': {'MACs': '(G): 155.69',\n",
       "  'tot_size': '(MB): 22799.37',\n",
       "  'trainable': 1619625},\n",
       " 'mst_plus_plus_768': {'MACs': '(G): 350.30',\n",
       "  'tot_size': '(MB): 51290.50',\n",
       "  'trainable': 1619625},\n",
       " 'mst_plus_plus_1024': {'MACs': '(G): 622.75',\n",
       "  'tot_size': '(MB): 91178.06',\n",
       "  'trainable': 1619625},\n",
       " 'vitmstpp_128': {'MACs': '(G): 16.49',\n",
       "  'tot_size': '(MB): 7695.43',\n",
       "  'trainable': 3320770,\n",
       "  'n_params': 92991682,\n",
       "  'gmac': 910.0643557310104},\n",
       " 'vitmstpp_256': {'MACs': '(G): 28.89',\n",
       "  'tot_size': '(MB): 8472.60',\n",
       "  'trainable': 3320770,\n",
       "  'n_params': 92991682,\n",
       "  'gmac': 922.1787194013596},\n",
       " 'vitmstpp_384': {'MACs': '(G): 49.56',\n",
       "  'tot_size': '(MB): 9767.88',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_512': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11581.27',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_768': {'MACs': '(G): 161.15',\n",
       "  'tot_size': '(MB): 16762.38',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_1024': {'MACs': '(G): 276.88',\n",
       "  'tot_size': '(MB): 24015.94',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_pad_128': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11575.37',\n",
       "  'trainable': 3320770,\n",
       "  'n_params': 92991682,\n",
       "  'gmac': 970.636174082756},\n",
       " 'vitmstpp_pad_256': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11576.55',\n",
       "  'trainable': 3320770,\n",
       "  'n_params': 92991682,\n",
       "  'gmac': 970.636174082756},\n",
       " 'vitmstpp_pad_384': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11578.51',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_pad_512': {'MACs': '(G): 78.49',\n",
       "  'tot_size': '(MB): 11581.27',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_pad_768': {'MACs': '(G): 161.15',\n",
       "  'tot_size': '(MB): 16762.38',\n",
       "  'trainable': 3320770},\n",
       " 'vitmstpp_pad_1024': {'MACs': '(G): 276.88',\n",
       "  'tot_size': '(MB): 24015.94',\n",
       "  'trainable': 3320770}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = 'restormer'\n",
    "model = model_generator(md).cuda()\n",
    "summary_str = str(torchinfo.summary(model, input_size=(1,3,1024,1024)))\n",
    "del model\n",
    "\n",
    "\n",
    "#models_dict[nm]['MACs'] = summary_str.split('Total mult-adds ')[1].split('\\n')[0]\n",
    "#models_dict[nm]['tot_size'] = summary_str.split('Estimated Total Size ')[1].split('\\n')[0]\n",
    "#models_dict[nm]['trainable'] = int(summary_str.split('Trainable params: ')[1].split('\\n')[0].replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for md in models: \n",
    "    print(md)\n",
    "    model = model_generator(md).cuda()\n",
    "    print('TORCHINFO')\n",
    "    print(torchinfo.summary(model, input_size=(2,3,256,256)))\n",
    "    #print('MY SUMMARY')\n",
    "    #print(my_summary(model, 256, 256, 3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model, input_size=(2,3,256,256)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model, input_size=(1,3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_summary(model, 256, 256, 31, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mst_compare_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
